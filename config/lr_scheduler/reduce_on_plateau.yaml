# @package _global_
lr_scheduler:
  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    mode: ${monitor_mode}
    factor: 0.5
    patience: 2
    min_lr: 1e-10 #1e-6
  monitor: ${monitor_metric}
  interval: epoch
